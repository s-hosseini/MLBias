# Census/xD Bias Resource Repository

 [![code style: prettier](https://img.shields.io/badge/code_style-prettier-ff69b4?style=for-the-badge)](https://github.com/prettier/prettier)



The US Census Bureau xD team, in collaboration with the [10x](https://10x.gsa.gov) program, is building a library of machine learning and artificial intelligence resources to help combat bias introduced by bias and algorithms. We aim to create toolkits to diverse audiences encompassing both technical and non-technical users. Furthermore, we hope to challenge people building machine learning products for government to consider how their product design choices might introduce bias exogenous to models and data.  

WHY: AI and machine learning-based tools, products, and methodologies are quickly being adopted and deployed across the US government. The rapid pace of adoption should raise ethical concerns to civil servants acquiring, building, or otherwise interacting with these ML-related solutions, particularly when these are invoked to make high-stakes decisions of relevance to the public. Invisible quality issues in datasets, biased data collection methods, bad data governance problems, misguided model development, and many other issues in the ML development cycle could introduce or amplify bias, affecting decision-making processes that adversely and systematically affect vulnerable populations served by government programs

WHAT: This collection currently includes a [syllabus for beginners, executable Jupyter Notebooks, an annotated list of resources](https://github.com/MLBiasgov/MLBias_papers), a [list of books used to build these resources](https://github.com/MLBiasgov/MLBias/blob/main/textbook%20reading%20list) and [other prototpye components including a Question and Answer flow used to guide users toward the appropriate resource list](https://github.com/MLBiasgov/MLBias/blob/main/MVP-Combating%20Bias%20in%20Government%20Data%20and%20Algorithms.pdf). 

A full public release is forthcoming in 2021.


